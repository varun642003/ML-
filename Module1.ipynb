{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this module, you'll be acquiring and handling datasets. You will be using the Cinema Data, Salary Data and Reviews Data for the tasks in this module. <br> <br>\n",
    "**Pipeline:**\n",
    "* Acquiring the data\n",
    "* Handling files and formats\n",
    "* Data Analysis\n",
    "* Prediction\n",
    "* Analysing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Handling\n",
    "* You can find the Reviews Data in a RAR file in the 'Data' directory. Extract this dataset and use it for this module.\n",
    "\n",
    "* The dataset contains positive and negative movie reviews. The files 'Positive_Reviews.txt' and 'Negative_Reviews.txt' contain names of files having positive and negative reviews respectively. Create two directories ‘pos’ and ‘neg’, and segregate the reviews accordingly into the two directories.\n",
    "\n",
    "* Load ‘cv000_29590.csv’ and report the number of words present in the first column.\n",
    "\n",
    "* Find the number of unique words in the first column. For this task, ignore punctuations, that is, punctuations are not considered as a word or a part of it.\n",
    "\n",
    "* Lookups: OS module, String functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\varun\\\\Downloads\\\\MLBasics-master\\\\MLBasics-master'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\varun\\\\Downloads\\\\Reviews\\\\Assignment_1_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Neg', 'Negative_Reviews.txt', 'Pos', 'Positive_Reviews.txt', 'Reviews']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Negative_Reviews.txt') as f:\n",
    "    temp = f.read()\n",
    "    \n",
    "temp = temp[1:-1]\n",
    "a=temp.replace(\", \",\" \")\n",
    "a=a.replace(\"'\",\"\")\n",
    "temp=a.split(\" \")\n",
    "for i in temp: \n",
    "    os.rename(f\"C:\\\\Users\\\\varun\\\\Downloads\\\\Reviews\\\\Assignment_1_a\\\\Reviews\\\\{i}\",f\"C:\\\\Users\\\\varun\\\\Downloads\\\\Reviews\\\\Assignment_1_a\\\\Neg\\\\{i}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Positive_Reviews.txt') as f:\n",
    "    temp = f.read()\n",
    "temp = temp[1:-1]\n",
    "a=temp.replace(\", \",\" \")\n",
    "a=a.replace(\"'\",\"\")\n",
    "temp=a.split(\" \")\n",
    "temp\n",
    "for i in temp:\n",
    "    os.rename(f\"C:\\\\Users\\\\varun\\\\Downloads\\\\Reviews\\\\Assignment_1_a\\\\Reviews\\\\{i}\",f\"C:\\\\Users\\\\varun\\\\Downloads\\\\Reviews\\\\Assignment_1_a\\\\Pos\\\\{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.read_csv(\"./Pos/cv000_29590.txt\")\n",
    "b=0\n",
    "for i in range(0,len(a.iloc[:,0])):\n",
    "    b+=len(a.iloc[:,0][i].split())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,\n",
       " ['starters',\n",
       "  'say',\n",
       "  'moore',\n",
       "  'campbell',\n",
       "  'thoroughly',\n",
       "  'researched',\n",
       "  'subject',\n",
       "  'would',\n",
       "  'like',\n",
       "  'saying',\n",
       "  'michael',\n",
       "  'jackson',\n",
       "  'starting',\n",
       "  'look',\n",
       "  'little',\n",
       "  'odd',\n",
       "  'or',\n",
       "  'graphic',\n",
       "  'novel',\n",
       "  'other',\n",
       "  'words',\n",
       "  'if',\n",
       "  'can',\n",
       "  'get',\n",
       "  'past',\n",
       "  'whole',\n",
       "  'book',\n",
       "  'thing',\n",
       "  'getting',\n",
       "  'hughes',\n",
       "  'brothers',\n",
       "  'direct',\n",
       "  'this',\n",
       "  'seems',\n",
       "  'almost',\n",
       "  'ludicrous',\n",
       "  'as',\n",
       "  'casting',\n",
       "  'carrot',\n",
       "  'top',\n",
       "  'ghetto',\n",
       "  'question',\n",
       "  'filthy',\n",
       "  'stiff',\n",
       "  'up',\n",
       "  'abberline',\n",
       "  'upon',\n",
       "  'arriving',\n",
       "  'whitechapel',\n",
       "  'think',\n",
       "  'anyone',\n",
       "  'needs',\n",
       "  'be',\n",
       "  'briefed',\n",
       "  'on',\n",
       "  'jack',\n",
       "  'ripper',\n",
       "  'comic',\n",
       "  'funny',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'locals',\n",
       "  'blindly',\n",
       "  'point',\n",
       "  'finger',\n",
       "  'of',\n",
       "  'blame',\n",
       "  'at',\n",
       "  'jews',\n",
       "  'indians',\n",
       "  'because',\n",
       "  'ending',\n",
       "  'me',\n",
       "  'whistling',\n",
       "  'stonecutters',\n",
       "  'song',\n",
       "  'simpsons',\n",
       "  'days',\n",
       "  'who',\n",
       "  'holds',\n",
       "  'back',\n",
       "  'electric',\n",
       "  'car/who',\n",
       "  'made',\n",
       "  'steve',\n",
       "  'guttenberg',\n",
       "  'a',\n",
       "  'star',\n",
       "  \"don't\",\n",
       "  'worry',\n",
       "  \"it'll\",\n",
       "  'all',\n",
       "  'make',\n",
       "  'sense',\n",
       "  'when',\n",
       "  'you',\n",
       "  'see',\n",
       "  'it',\n",
       "  'now',\n",
       "  'onto',\n",
       "  \"hell's\",\n",
       "  'appearance',\n",
       "  \"it's\",\n",
       "  'certainly',\n",
       "  'dark',\n",
       "  'bleak',\n",
       "  'enough',\n",
       "  'print',\n",
       "  'saw',\n",
       "  \"wasn't\",\n",
       "  'completely',\n",
       "  'finished',\n",
       "  'both',\n",
       "  'color',\n",
       "  'music',\n",
       "  'had',\n",
       "  'not',\n",
       "  'been',\n",
       "  'finalized',\n",
       "  'oscar',\n",
       "  'winner',\n",
       "  'martin',\n",
       "  \"childs'\",\n",
       "  'shakespeare',\n",
       "  'love',\n",
       "  'production',\n",
       "  'design',\n",
       "  'turns',\n",
       "  'original',\n",
       "  'prague',\n",
       "  'surroundings',\n",
       "  'into',\n",
       "  'one',\n",
       "  'creepy',\n",
       "  'place',\n",
       "  'even',\n",
       "  'acting',\n",
       "  'from',\n",
       "  'hell',\n",
       "  'is',\n",
       "  'solid',\n",
       "  'ians',\n",
       "  'holm',\n",
       "  'joe',\n",
       "  \"gould's\",\n",
       "  'secret',\n",
       "  'and',\n",
       "  'richardson',\n",
       "  '102',\n",
       "  'dalmatians',\n",
       "  'log',\n",
       "  'in',\n",
       "  'great',\n",
       "  'supporting',\n",
       "  'roles',\n",
       "  'i',\n",
       "  'cringed',\n",
       "  'first',\n",
       "  'time',\n",
       "  'she',\n",
       "  'opened',\n",
       "  'her',\n",
       "  'mouth',\n",
       "  'the',\n",
       "  'film',\n",
       "  '2',\n",
       "  '00',\n",
       "  'r',\n",
       "  'for',\n",
       "  'strong',\n",
       "  'violence/gore'])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.read_csv(\"./Pos/cv000_29590.txt\")\n",
    "x=[]\n",
    "for i in range(0,len(a.iloc[:,0])):\n",
    "    x.append(a.iloc[:,0][i].split())\n",
    "z=list(np.concatenate(x))\n",
    "y1=\".\"\n",
    "y2=\"(\"\n",
    "y3='\"'\n",
    "y4=\"?\"\n",
    "y5=\")\"\n",
    "y6=\"-\"\n",
    "y7=\":\"\n",
    "while y1 in z:\n",
    "    z.remove(y)\n",
    "while y2 in z:\n",
    "    z.remove(y2)\n",
    "while y3 in z:\n",
    "    z.remove(y3)\n",
    "while y4 in z:\n",
    "    z.remove(y4)    \n",
    "while y5 in z:\n",
    "    z.remove(y5)\n",
    "while y6 in z:\n",
    "    z.remove(y6)\n",
    "while y7 in z:\n",
    "    z.remove(y7)     \n",
    "for i in z:\n",
    "    while z.count(i)-1:\n",
    "        z.remove(i)       \n",
    "len(z),z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
